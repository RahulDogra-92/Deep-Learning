{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolutional Neural Networks",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahulDogra-92/Deep-Learning-using-Pytorch/blob/main/Convolutional_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akC2DZ8ztOLN"
      },
      "source": [
        "#Convolutions in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0APAhBtrh71"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc6knaNEr5Jg"
      },
      "source": [
        "image = torch.rand(16,3,32,32)\n",
        "filter = torch.rand(1,3,5,5)\n",
        "out_feat_F = F.conv2d(image, filter, stride=1, padding=0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux5sfyy-sXVU",
        "outputId": "f8aff277-624d-450f-cf9b-ed39a9396d83"
      },
      "source": [
        "print(out_feat_F.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIPr7ed1tkMj"
      },
      "source": [
        "#Convolution operator - Functional way\n",
        "how to build convolutional layers using functional package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgsKmFUesZ9i",
        "outputId": "5ff34fdf-e0af-4149-85b5-a198a0fe0a95"
      },
      "source": [
        "# Create 10 random images\n",
        "image = torch.rand(10, 1, 28, 28)\n",
        "\n",
        "# Create 6 filters\n",
        "filters = torch.rand(6, 1, 3, 3)\n",
        "\n",
        "# Convolve the image with the filters\n",
        "output_feature = F.conv2d(image, filters, stride=1, padding=1)\n",
        "print(output_feature.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 6, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paRCQ2fBunbu"
      },
      "source": [
        "#Max-pooling in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th_vtzkZuMm9"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBOy2Guouwkv",
        "outputId": "6caac9e2-4067-4327-ebd1-6fd0cc5ed41f"
      },
      "source": [
        "im = torch.Tensor([[[[3, 1, 3, 5], [6, 0, 7, 9],\n",
        "                     [3, 2, 1, 4], [0, 2, 4, 3]]]])\n",
        "\n",
        "output_feature_F = F.max_pool2d(im, 2)\n",
        "print(output_feature_F)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[6., 9.],\n",
            "          [3., 4.]]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXsMO2w2vBnO",
        "outputId": "d2433016-5cdc-488f-cd7f-d61a1d6c7b35"
      },
      "source": [
        "im = torch.Tensor([[[[3, 1, 3, 5], [6, 0, 7, 9],\n",
        "                     [3, 2, 1, 4], [0, 2, 4, 3]]]])\n",
        "\n",
        "output_feature_F = F.avg_pool2d(im, 2)\n",
        "print(output_feature_F)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[2.5000, 6.0000],\n",
            "          [1.7500, 3.0000]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQpEjJhawCVW"
      },
      "source": [
        "#Max-pooling operator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjKi6ueNvXHo",
        "outputId": "7d4ba052-59a7-428f-d2a4-880f6461dd9f"
      },
      "source": [
        "# Build a pooling operator with size `2`.\n",
        "max_pooling = torch.nn.MaxPool2d(2)\n",
        "\n",
        "# Apply the pooling operator\n",
        "output_feature = max_pooling(im)\n",
        "\n",
        "# Use pooling operator in the image\n",
        "output_feature_F = F.max_pool2d(im, 2)\n",
        "\n",
        "# print the results of both cases\n",
        "print(output_feature)\n",
        "print(output_feature_F)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[6., 9.],\n",
            "          [3., 4.]]]])\n",
            "tensor([[[[6., 9.],\n",
            "          [3., 4.]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di17evimxSJk"
      },
      "source": [
        "#Average-pooling operator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofgwiC6CwnJw",
        "outputId": "47c2cb8c-30b3-45f0-db89-1c014d3540e0"
      },
      "source": [
        "# Build a pooling operator with size `2`.\n",
        "avg_pooling = torch.nn.AvgPool2d(2)\n",
        "\n",
        "# Apply the pooling operator\n",
        "output_feature = avg_pooling(im)\n",
        "\n",
        "# Use pooling operator in the image\n",
        "output_feature_F = F.avg_pool2d(im, 2)\n",
        "\n",
        "# print the results of both cases\n",
        "print(output_feature)\n",
        "print(output_feature_F)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[2.5000, 6.0000],\n",
            "          [1.7500, 3.0000]]]])\n",
            "tensor([[[[2.5000, 6.0000],\n",
            "          [1.7500, 3.0000]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AldEKH0xb3f"
      },
      "source": [
        "#Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBD6AHCJ16Gv"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBmXCfwc19-f"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkbkuNXB2h2e"
      },
      "source": [
        "#Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBb-i0lz2Zx5",
        "outputId": "15cae500-8399-4661-956a-e8289603fa3d"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914, 0.48216, 0.44543),\n",
        "                          (0.24703, 0.24349, 0.26519))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train = True, download = True, transform = transform)\n",
        "testset = torchvision.datasets.CIFAR10(root=\"./data\", train = False, download = True, transform = transform)\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle = True, num_workers = 4)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle = False, num_workers = 4)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6brU77u52vOo"
      },
      "source": [
        "#Building a CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaB8CUxH2kE3"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.fc = nn.Linear(128 * 4 * 4, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.pool(F.relu(self.conv3(x)))\n",
        "    x = x.view(-1, 128 * 4 * 4)\n",
        "    return self.fc(x)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WqN6XSgmu7j"
      },
      "source": [
        "#Optimizer and Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRJaB-2q3BeF"
      },
      "source": [
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=3e-4)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzgPcoJwnwo1"
      },
      "source": [
        "#Training a CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lryXqCjnGU3",
        "outputId": "7f39efe7-d7e9-48a3-8e54-e906b6f13174",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(10):\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "    #get the inputs\n",
        "    inputs, labels = data\n",
        "\n",
        "    #Zero the parameters the gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #Forward + backward + optimize\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()      #Compute the weights using backward()\n",
        "    optimizer.step()     #Update the weights using optimizer\n",
        "\n",
        "print('Finised Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtFD3j02pgVv"
      },
      "source": [
        "#Evaluating the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_sXY638ozvm"
      },
      "source": [
        "correct, total = 0,0\n",
        "predictions = []\n",
        "net.eval()\n",
        "\n",
        "for i, data in enumerate(testloader, 0):\n",
        "  inputs, labels = data\n",
        "  outputs = net(inputs)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  predictions.append(outputs)\n",
        "  total += label.size(0)\n",
        "  correct += (predicted ==labels).sum().item()\n",
        "\n",
        "print('The testing set accuracy of the network is: %d %%' % (\n",
        "    100 * correct / total))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck6fl4w2qhV2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}