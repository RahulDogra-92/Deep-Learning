{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Captioning using CNN and LSTM",
      "provenance": [],
      "authorship_tag": "ABX9TyMwh2Eaj3/cKHvXo3TG5O8f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahulDogra-92/Deep-Learning-using-Pytorch/blob/main/Image_Captioning_using_CNN_and_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_mJkCC89ALc",
        "outputId": "3fb5a9c5-c206-4967-cf1a-0d6b5a3eed11"
      },
      "source": [
        "pip install scipy==1.1.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjCebL_57DXa"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import h5py\n",
        "import json\n",
        "import torch\n",
        "from scipy.misc import imread, imresize\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from random import seed, choice, sample\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn.utils.rnn import pack_padded_sequence"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XAglW3R9Ifk"
      },
      "source": [
        "def save_checkpoint(epoch, encoder, decoder, decoder_optimizer):\n",
        "\n",
        "  state = {'epoch': epoch,\n",
        "           'encoder': encoder,\n",
        "           'decoder': decoder,\n",
        "           'decoder_optimizer': decoder_optimizer}\n",
        "\n",
        "  filename = 'checkpoint' + str(epoch) + '.pth'\n",
        "  torch.save(state, filename)\n",
        "\n",
        "class AverageMeter(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.val = 0\n",
        "    self.avg = 0\n",
        "    self.sum = 0\n",
        "    self.count = 0\n",
        "\n",
        "  def update(self, val, n=1):\n",
        "      self.val = val\n",
        "      self.sum = val * n\n",
        "      self.count+=n\n",
        "      self.avg = self.sum / self.count\n",
        "\n",
        "  def adjust_learning_rate(optimizer, shrink_factor):\n",
        "    optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] *  shrink_factor\n",
        "    print(\"The new learning rate is : {:.3f}\" .format(optimizer.param_groups[0]['lr']))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTPUpXxbADuq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}